{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1834a4d",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "### This is a sample script for the data cleaning process in our project. The actual scripts would change depending on each dataset's characteristics and different purposes/models of using each dataset.\n",
    "\n",
    "Team Member: Zeyu Gu, Yansong Bai, Yuzheng Zhang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c171e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import sklearn.metrics\n",
    "import scipy.stats as st\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy import stats\n",
    "import optuna\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980dfcb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data preview\n",
    "# data = pd.read_csv('city_ranking.csv')\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd3e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1934e6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa1396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the missing data\n",
    "percent_missing = (data.isnull().sum() / len(data)).to_frame()\n",
    "percent_missing.columns= ['Missing data %']\n",
    "percent_missing.sort_values(by = 'Missing data %', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc91e5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise missing values for a sample of 500\n",
    "msno.matrix(data.sample(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394167bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns with percents of missing value exceed the threshold\n",
    "# The threshold dependends on the specific attribute in the datasets and some special features\n",
    "# should not be drop although the missing percent is high due to the \n",
    "drop_cols = [a for a in percent_missing[percent_missing[\"Missing data %\"]>0.75].index]\n",
    "data.drop(drop_cols,axis = 1,inplace= True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f75657",
   "metadata": {},
   "source": [
    "### Sometimes we just kept the missing value as NA since ML models like Graient Boosting Tree still have a good performance in tolerance of the existence of NA values.\n",
    "### Othewise we used imputations for the missing value such as mean value imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cef9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes we could just keep the missing value as NA \n",
    "# since some ML models like Graient Boosting Tree still have a good performancein tolerance of the existence of NA values\n",
    "# Othewise we used imputation for the missing value ex: mean value imputation\n",
    "\n",
    "data[data.columns[idx]] = data[data.columns[idx]].fillna(data[data.columns[idx]].meam()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a93b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate skewness and kurtosis\n",
    "data.skew(), data.kurt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9299c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate categories with fewer than 10 obs to the new category \"Rare\"\n",
    "def transfer_rare_val(data,attr_name):\n",
    "    val_counts = data[attr_name].value_counts()\n",
    "    rare_val = val_counts.index[np.where(val_counts<=10)]\n",
    "    data.loc[(data[attr_name].isin(rare_val)) & (data[attr_name]!=None),[attr_name]] = 'Rare'\n",
    "    \n",
    "    \n",
    "transfer_rare_val(data,data.columns[2])\n",
    "transfer_rare_val(data,data.columns[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8447cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check outliers for columns that are normal distributed\n",
    "def clean_outliers(idx):\n",
    "    display(sns.boxplot(data=data[data.columns[idx]]))\n",
    "    data.loc[(data[data.columns[idx]]<data[data.columns[idx]].mean() - 2 * data.std()[idx])|\n",
    "              (data[data.columns[idx]]>data[data.columns[idx]].mean() + 2 * data.std()[idx]),\n",
    "              data.columns[idx]]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbf847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_outliers(2)\n",
    "clean_outliers(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8c649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example when clean some special columns of data:\n",
    "\n",
    "# Clean for ZIP\n",
    "data.loc[(data['ZIP'].str.slice(0,2) != '89'),['ZIP']] = 'WrongValue'\n",
    "data['ZIP'] = data['ZIP'].str.slice(0,5)\n",
    "data[data['ZIP'].str.slice(0,2) != '89']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f3fb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean for column of CITY_TYPE\n",
    "\n",
    "# Set CITY_TYPE that are not 'Global','Cosmopolitan','Planned', 'Emergent' to None\n",
    "data['CITY_TYPE'].value_counts()\n",
    "data.loc[(data['CITY_TYPE'].isin(['Global','Cosmopolitan','Planned', 'Emergent'])),['CITY_TYPE']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b1afa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean for column of LAT_LONG_RAW\n",
    "data['LAT_LONG_RAW'] = data['LAT_LONG_RAW'].str.replace('(', '')\n",
    "data['LAT_LONG_RAW'] = data['LAT_LONG_RAW'].str.replace(')', '')\n",
    "data[['LAT','LONG']] = data['LAT_LONG_RAW'].str.split(',',expand=True)\n",
    "data['LAT'] = abs(pd.to_numeric(data['LAT']))\n",
    "data['LONG'] = abs(pd.to_numeric(data['LONG']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63c826c",
   "metadata": {},
   "source": [
    "### Encode features and detect multicollinearity as preparation before modeling (in our recommendation page):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673aef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine numerical features in the dataset\n",
    "numeric_features = data.select_dtypes(include=[np.number])\n",
    "numeric_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391fb8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes(include='number').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61b9859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine categorical features in the dataset\n",
    "categorical_features = data.select_dtypes(include=[np.object])\n",
    "categorical_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ce211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use Label enoder to encode variables as the preparation for the ML models in our recommendation page\n",
    "# example 1 \n",
    "data[data.select_dtypes(include=['category']).columns] = data[data.select_dtypes(include=['category']).columns].astype(str)\n",
    "data[categorical_features.columns] = data[categorical_features.columns].astype(str)\n",
    "data[categorical_features.columns] = data[categorical_features.columns].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "# example 2 \n",
    "categorical = data.columns[[4, 6, 8,10]]\n",
    "ordinal = data.columns[[1,3,4,5]]\n",
    "label = data.columns[[2,7]]\n",
    "\n",
    "data[categorical] = data[categorical].astype('str')\n",
    "enc = OrdinalEncoder()\n",
    "enc.fit(data[ordinal])\n",
    "data[ordinal] = enc.transform(data[ordinal])\n",
    "data[label] = data[label].apply(LabelEncoder().fit_transform)\n",
    "data[categorical] = data[categorical].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b508ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the correlation between numerical variables\n",
    "data[numeric_features.columns].corr().style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf77db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes we need to check the existence of multicollinearity of potential independent variables\n",
    "# So we get the VIF for each variable to detect multicollinearity\n",
    "\n",
    "def get_vif(X_vif):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = X_vif.columns\n",
    "\n",
    "    # calculating VIF for each feature\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X_vif.values, i)\n",
    "                              for i in range(len(X_vif.columns))]\n",
    "    vif_data = vif_data.sort_values('VIF', ascending=False)\n",
    "    print(vif_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c030c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove each variable with high one by one to avoid unnecessary removement and infomation loss\n",
    "X_vif = data.drop(\"University Score\", axis = 1)\n",
    "get_vif(X_vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960b0963",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vif = data.drop(\"Employment Score\", axis = 1)\n",
    "get_vif(X_vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff42594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration graphs\n",
    "# example:\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x = data[data.columns[idx]], y = y)\n",
    "plt.ylabel('Satisfaction')\n",
    "plt.xlabel('Food Ranking')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06988d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histplot example:\n",
    "sns.histplot(data=data,x=data.columns[idx], hue='Preference')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
